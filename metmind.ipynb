{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "metmind.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKvBQ20eb5dd"
      },
      "source": [
        "#This code has been inspired by the works of:\n",
        "# 1: ugik (2017) Tensorflow chat-bot model.ipynb Available At: https://github.com/ugik/notebooks/blob/master/Tensorflow%20chat-bot%20model.ipynb (Accessed: 2/02/2020)\n",
        "# 2: FreeBirdsCrew (2020) CHATBOTS - Using Natural Language Processing and Tensorflow Available At: https://github.com/FreeBirdsCrew/AI_ChatBot_Python/blob/master/Contextual%20Chatbot%20-%20NLP%20and%20Tensorflow.ipynb (Accessed: 6/02/2020)\n",
        "# 3: Tech With Tim (2019) Python Chat Bot Tutorial - Chatbot with Deep Learning (Part 3) Available At: https://www.youtube.com/watch?v=PzzHOvpqDYs&ab_channel=TechWithTim (Accessed: 16/10/2020)\n",
        "# 4: Tech With Tim (2019) Python Chat Bot Tutorial - Chatbot with Deep Learning (Part 2) Available At: https://www.youtube.com/watch?v=ON5pGUJDNow (Accessed: 16/10/2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwYlg8bwDhjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae425482-4374-4528-d5f1-84f01ed24293"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNr2eHgMDtJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b4722e-e474-4e21-96a4-3dba14b5326a"
      },
      "source": [
        "pip install tflearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Nszpz-EkP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3463435-8bd9-45be-89b8-8c3fbfb2895a"
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxLcc0mJzsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e300f5f-5a53-44d7-a3c7-f6e42eb5fcbe"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veLjVxEVqsDU"
      },
      "source": [
        "from IPython.display import Javascript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gNHg_8uwQW6"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdtkJO5W-1gr"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "import pickle\n",
        "import math\n",
        "import binascii\n",
        "import webbrowser\n",
        "import urllib.error\n",
        "import urllib.request\n",
        "import smtplib\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odEmd-yTF4lR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22a4dfb9-2492-40aa-ed1e-c98ef439b3ca"
      },
      "source": [
        "tf.version.VERSION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_93JSb9EN8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a509eb-a7bb-4800-c1d7-1850b5a7b98d"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkGfl4MQpCX"
      },
      "source": [
        "qaCode = binascii.unhexlify(\"5468616e6b20796f7520666f722070617274696369706174696e6720666f72203130206d696e75746573212054686520436f646520666f7220746865207175657374696f6e6e61697265206973204135337274593133322120596f752063616e206b6565702074657374696e6720696620796f752077616e743a203c62722f3e3c62722f3e\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzpMkYfR_HHZ"
      },
      "source": [
        "try:\n",
        "  with open('intents.json') as json_data:\n",
        "      intents = json.load(json_data)\n",
        "except FileNotFoundError:\n",
        "  print(\"json file not found\")\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvIwj_TGl28J"
      },
      "source": [
        "files = [\"./templates/index.html\", \"./static/pop.mp3\", \"./static/css/style.css\"]\n",
        "for item in files:\n",
        "  if os.path.isfile(item):\n",
        "    continue\n",
        "  else:\n",
        "    print(item + \" does not exist in the correct directory! Please refer back to the guidelines found in the email\")\n",
        "    sys.exit('Closing Program')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSC66RZT_LfU"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ-S1zcL_Nlz"
      },
      "source": [
        "#This section is designed to loop through each pattern in an intent\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #This section is designed for tokenization: This will be proccessed to all words in a sentence\n",
        "        try:\n",
        "          w = nltk.word_tokenize(pattern)\n",
        "        except LookupError as ntlkerror:\n",
        "          print(\"Error during tokenization: \", ntlkerror)\n",
        "          sys.exit('Closing Program')\n",
        "\n",
        "        words.extend(w)\n",
        "        documents.append((w, intent['tag']))\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFMrXqRI_Qll"
      },
      "source": [
        "#This section is designed for stemming each word\n",
        "#This section will also ensure that any capital letter will be tranformed to lower case\n",
        "try:\n",
        "  words = [stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
        "  words = sorted(list(set(words)))\n",
        "except IndexError:\n",
        "  print(\"Error stemming words\")\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sst6ntm_SjE"
      },
      "source": [
        "\n",
        "classes = sorted(list(set(classes)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmNrwzZAAVRT"
      },
      "source": [
        "training = []\n",
        "output = []\n",
        "output_empty = [0] * len(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehuJjHOoAYl0"
      },
      "source": [
        "# This section is designed to transform each sentence into a BOW[Bag of Words]\n",
        "for doc in documents:\n",
        "    bag_of_words = []\n",
        "    pattern_words = doc[0]\n",
        "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "\n",
        "    for w in words:\n",
        "      if w in pattern_words:\n",
        "        bag_of_words.append(1)\n",
        "      else:\n",
        "        bag_of_words.append(0)\n",
        "\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag_of_words, output_row])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9lWmzkZAmwG"
      },
      "source": [
        "random.shuffle(training)\n",
        "training = np.array(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njatqhJxAqY9"
      },
      "source": [
        "# This will create our training and testing data as lists\n",
        "train_x = list(training[:, 0])\n",
        "train_y = list(training[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9-22d2AsaV"
      },
      "source": [
        "try:\n",
        "  tf.reset_default_graph()\n",
        "except AttributeError as tfgrapherror:\n",
        "  print(\"Error resetting tensorflow graph: \", tfgrapherror)\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb90R_4iAu_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c759ab-7a8f-4b25-e47f-0ddde7515677"
      },
      "source": [
        "try:\n",
        "  hiddenLayerNode = math.ceil(((len(train_x[0]) + len(train_y[0])) / 2))\n",
        "  net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "  net = tflearn.fully_connected(net, hiddenLayerNode)\n",
        "  net = tflearn.fully_connected(net, math.ceil((hiddenLayerNode / 2)))\n",
        "  net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
        "  net = tflearn.regression(net)\n",
        "except ValueError as nnbuilderror:\n",
        "  print(\"Error creating the neural network model: \", nnbuilderror)\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUfZldXcAFHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03545952-1de4-416b-d20b-8fd7cedd5e62"
      },
      "source": [
        "#If path is not in directory try to create folder ./tflearnModel\n",
        "if not os.path.isdir('./tflearnModel'):\n",
        "    try:\n",
        "        os.mkdir(\"./tflearnModel\")\n",
        "    except OSError:\n",
        "        print(\"Creation of the directory failed\")\n",
        "        sys.exit('Closing Program')\n",
        "    else:\n",
        "        print(\"Successfully created the directory\")\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully created the directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj_NZvXdAzRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4cf0c81-f189-4b5e-81f3-4c1741ef92cd"
      },
      "source": [
        "# This section is designed to created our neural networking model\n",
        "try:\n",
        "  model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
        "  # Start training (apply gradient descent algorithm)\n",
        "  model.fit(train_x, train_y, n_epoch=100, batch_size=32, show_metric=True)\n",
        "  model.save('./tflearnModel/model.tflearn')\n",
        "except IndexError as nnfiterror:\n",
        "  print(\"Error fitting the neural network model: \", nnfiterror)\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 2499  | total loss: \u001b[1m\u001b[32m0.00276\u001b[0m\u001b[0m | time: 0.195s\n",
            "| Adam | epoch: 100 | loss: 0.00276 - acc: 0.9993 -- iter: 768/782\n",
            "Training Step: 2500  | total loss: \u001b[1m\u001b[32m0.00255\u001b[0m\u001b[0m | time: 0.201s\n",
            "| Adam | epoch: 100 | loss: 0.00255 - acc: 0.9994 -- iter: 782/782\n",
            "--\n",
            "INFO:tensorflow:/content/tflearnModel/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0A_DTioA4Ok"
      },
      "source": [
        "#Try to pickle words/classes and training data as to convert and save  words/classes and training data into bytes.\n",
        "try:\n",
        "  pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y},\n",
        "              open(\"./tflearnModel/model.tflearn\", \"wb\"))\n",
        "except (IOError, OSError, pickle.PickleError, pickle.UnpicklingError):\n",
        "  print(\"Error writing/saving pickled data as tflearn model\")\n",
        "  sys.exit(\"Closing Program\")\n",
        "except FileNotFoundError:\n",
        "  print(\"tflearn model does not exist\")\n",
        "  sys.exit(\"Closing Program\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aBNbR_8A-Gq"
      },
      "source": [
        "try:\n",
        "  data = pickle.load(open(\"./tflearnModel/model.tflearn\", \"rb\"))\n",
        "except (IOError, OSError, pickle.PickleError, pickle.UnpicklingError):\n",
        "  print(\"Error loading pickled data from tflearn model\")\n",
        "  sys.exit(\"Closing Program\")\n",
        "except FileNotFoundError:\n",
        "  print(\"tflearn model does not exist\")\n",
        "  sys.exit(\"Closing Program\")\n",
        "\n",
        "words = data['words']\n",
        "classes = data['classes']\n",
        "train_x = data['train_x']\n",
        "train_y = data['train_y']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L16OwfUJBD2d"
      },
      "source": [
        "class ContextHistory:\n",
        "    contextOld = \"\"\n",
        "    myIntent = \"\"\n",
        "    myOldTag = \"\"\n",
        "    myTag = \"\"\n",
        "    myFirstContext = \"\"\n",
        "\n",
        "    myFirstInput = 0\n",
        "\n",
        "    myEmailIntent = 0\n",
        "    studentEmail = \"\"\n",
        "    studentPassword = \"\"\n",
        "    staffEmail = \"\"\n",
        "    symptomType = \"\"\n",
        "    symptomProblem = \"\"\n",
        "\n",
        "    time = 0.0\n",
        "    startTime = 0.0\n",
        "\n",
        "    chatRestart = \"<br/><br/>Please specify if you want \" \\\n",
        "                  \"guidance for your <fears> or anxiety <symptoms> whilst at Cardiff Met during the coronavirus \" \\\n",
        "                  \"epidemic. Input (fears) or (symptoms)\"\n",
        "myOldContext = ContextHistory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA4hJzDiBYb0"
      },
      "source": [
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMxUkZQsBcIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e2dfb1-7eb3-4ccf-b565-2e862d2fc24e"
      },
      "source": [
        "model.load('./tflearnModel/model.tflearn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/tflearnModel/model.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B72wL7GdBfcy"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    #This is designed to tokenize the  user input\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    #This is designed to stem the words from the users inputs\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4wvklXfBi86"
      },
      "source": [
        "def bow(sentence, words, show_details=False):\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    bag_of_words = [0] * len(words)\n",
        "    for s in sentence_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag_of_words[i] = 1\n",
        "                if show_details:\n",
        "                    print(\"found in bag: %s\" % w)\n",
        "\n",
        "    return np.array(bag_of_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8mOrk-xBl68"
      },
      "source": [
        "def myTime():\n",
        "    if ContextHistory.myFirstInput < 1:\n",
        "        ContextHistory.startTime = time.perf_counter()\n",
        "\n",
        "    ContextHistory.time = (time.perf_counter() - ContextHistory.startTime)\n",
        "    print(ContextHistory.time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoCjWt8hBomo"
      },
      "source": [
        "context = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNLHHc-QBrQG"
      },
      "source": [
        "ERROR_THRESHOLD = 0.70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ63hKEOBs9O"
      },
      "source": [
        "def classify(sentence):\n",
        "    #This section is designed to calculate the probability values from the users input to the model\n",
        "    results = model.predict([bow(sentence, words)])[0]\n",
        "    #If a prediction is below the error thresehold of 0.70 then it is filtered out\n",
        "    results = [[i, r] for i, r in enumerate(results) if r > ERROR_THRESHOLD]\n",
        "    #Calculates and sorts the probability rates comparing to its strength/probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1]))\n",
        "\n",
        "    return return_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpifGB7VB1H4"
      },
      "source": [
        "def filtering(i, show_details):\n",
        "    if 'context_set' in i:\n",
        "        if show_details:\n",
        "            return 'context:', i['context_set']\n",
        "        myOldContext.contextOld = i['context_set']\n",
        "        myOldContext.myTag = i['tag']\n",
        "        return i['context_set']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKl5hIHLB5Bs"
      },
      "source": [
        "def advancedResponse(i):\n",
        "    if 'web' in i:\n",
        "        myWeb = i['web']\n",
        "        try:\n",
        "            urllib.request.urlopen(myWeb)\n",
        "        except urllib.error.HTTPError:\n",
        "            return \"I am sorry but I am having trouble connecting to the site: \" + random.choice(i['responses'])\n",
        "        except urllib.error.URLError:\n",
        "            return \"I am sorry but I am having trouble connecting to the site\" + random.choice(i['responses'])\n",
        "        else:\n",
        "            url = myWeb\n",
        "            display(Javascript('window.open(\"{url}\");'.format(url=url)))\n",
        "            return \"Redirecting: \" + random.choice(i['responses'])\n",
        "\n",
        "    else:\n",
        "        return random.choice(i['responses'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wn2oKK_B764"
      },
      "source": [
        "def email(userInput):\n",
        "    if myOldContext.myEmailIntent == 1:\n",
        "        myOldContext.studentEmail = str(userInput) + \"@outlook.cardiffmet.ac.uk\"\n",
        "        print(str(userInput) + \"from email\")\n",
        "        myOldContext.myEmailIntent += 1\n",
        "        return \"Please Enter Your Student Password\"\n",
        "    else:\n",
        "        recEmail = myOldContext.staffEmail\n",
        "        subject = myOldContext.studentEmail + \" \" + myOldContext.symptomType + \" anxiety symptom issues\"\n",
        "        body = \"Dear Sir/Madam,\\n\\n This student has been recorded at a high priority as the participant has shown \" \\\n",
        "               \"signs of suffering from severe \" + myOldContext.symptomType + \" anxiety symptoms. The symptoms \" \\\n",
        "                                                                              \"specified indicate that the \" \\\n",
        "                                                                              \"student could be suffering from \" \\\n",
        "                                                                              \"anxities that can lead to \" + \\\n",
        "               myOldContext.symptomProblem + \"\\n\\nPlease Email them as soon as possible as to arrange a formal meetup \" \\\n",
        "                                             \"and/or conversation. \\n\\n Kindest Regards\\nMetMind Chatbot\"\n",
        "        msg = f'Subject: {subject}\\n\\n{body}'\n",
        "\n",
        "        myOldContext.studentPassword = str(userInput)\n",
        "\n",
        "        try:\n",
        "            server = smtplib.SMTP('smtp.outlook.com', 587)\n",
        "            server.starttls()\n",
        "            server.login(myOldContext.studentEmail, myOldContext.studentPassword)\n",
        "            server.sendmail(myOldContext.studentEmail, recEmail, msg)\n",
        "            myOldContext.myEmailIntent = 0\n",
        "            myOldContext.contextOld = \"\"\n",
        "            myOldContext.myFirstContext = \"\"\n",
        "            myOldContext.myIntent = \"\"\n",
        "            myOldContext.myOldTag = myOldContext.chatRestart\n",
        "            return \"email sent! you will hear from the wellbeing team shortly\" + myOldContext.chatRestart\n",
        "        except smtplib.SMTPAuthenticationError:\n",
        "            myOldContext.myEmailIntent = 1\n",
        "            return \"Incorrect email or password: please enter your username\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3yTCLpsCAOo"
      },
      "source": [
        "def response(sentence, userID='123', show_details=False):\n",
        "    results = classify(sentence)\n",
        "    #If the user input is correctly classified find matching intent/tag\n",
        "    if results:\n",
        "        #Loop through possible matches\n",
        "        print(results)\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                #Get tag from first result(if matching)\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    \n",
        "                    if 'email' in i:\n",
        "                        myOldContext.myEmailIntent = 1\n",
        "                        myOldContext.staffEmail = i['email']\n",
        "                        myOldContext.symptomType = i['symptom_type']\n",
        "                        myOldContext.symptomProblem = i['symptom_problem']\n",
        "\n",
        "                    if 'context_set' in i and 'context_filter' not in i and myOldContext.myFirstContext == \"\":\n",
        "                        myOldContext.myOldTag = random.choice(i['responses'])\n",
        "                        myOldContext.myFirstContext = i['context_set']\n",
        "                        myOldContext.myIntent = i['intent']\n",
        "\n",
        "                    try:\n",
        "                        if ('intent' in i and i['context_filter'] == myOldContext.contextOld) or (i['tag'] == myOldContext.myTag):\n",
        "                            myOldContext.myOldTag = random.choice(i['responses'])\n",
        "                            myOldContext.myIntent = i['intent']\n",
        "                            print(myOldContext.myIntent)\n",
        "\n",
        "                    except KeyError:\n",
        "                        print(\"Filter Not In Requested Object\")\n",
        "\n",
        "                    \n",
        "                    print(myOldContext.myOldTag)\n",
        "                    print(myOldContext.contextOld)\n",
        "\n",
        "                    if 'context_filter' in i and i['context_filter'] == myOldContext.contextOld:\n",
        "                        context[userID] = filtering(i, show_details)\n",
        "                        if 'context_set' not in i and myOldContext.myEmailIntent < 1:\n",
        "                            myOldContext.contextOld = \"\"\n",
        "                            myOldContext.myIntent = \"\"\n",
        "                            myOldContext.myFirstContext = \"\"\n",
        "                            myOldContext.myOldTag = myOldContext.chatRestart\n",
        "                            myResp = advancedResponse(i) + myOldContext.chatRestart\n",
        "                        else:\n",
        "                            myResp = advancedResponse(i)\n",
        "                        print(\"reached\")\n",
        "                        return myResp\n",
        "                    elif 'context_filter' not in i and myOldContext.contextOld != \"\" or (\n",
        "                            'context_filter' in i and i['context_filter'] != myOldContext.contextOld):\n",
        "                        return \"I'm sorry? Can you repeat that?: \" + myOldContext.myOldTag\n",
        "                    else:\n",
        "                        context[userID] = filtering(i, show_details)\n",
        "\n",
        "                        if 'context_filter' not in i or \\\n",
        "                                (userID in context and 'context_filter' in i and i['context_filter'] == context[\n",
        "                                    userID]):\n",
        "                            if show_details:\n",
        "                                return 'tag:', i['tag']\n",
        "                            # a random response from the intent\n",
        "                            return random.choice(i['responses'])\n",
        "\n",
        "            results.pop(0)\n",
        "    else:\n",
        "        if myOldContext.myIntent != \"\":\n",
        "            return \"I'm sorry? Can you repeat that?: \" + myOldContext.myOldTag\n",
        "        else:\n",
        "            return \"I'm sorry? Can you repeat that?: \" + myOldContext.myOldTag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4otdGb7HCHZt"
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3d6UXFNCJYo"
      },
      "source": [
        "@app.route('/get')\n",
        "def userChat():\n",
        "    myStr = \"\"\n",
        "    if ContextHistory.time > 600.00 and ContextHistory.myFirstInput != 2:\n",
        "        ContextHistory.myFirstInput = 2\n",
        "\n",
        "        myStr += qaCode.decode()\n",
        "\n",
        "    userInput = request.args.get('msg')\n",
        "    myTime()\n",
        "\n",
        "    if myOldContext.myEmailIntent != 0:\n",
        "        myStr = email(userInput)\n",
        "    else:\n",
        "        if myOldContext.myIntent != \"\":\n",
        "            userInput = myOldContext.myIntent + userInput\n",
        "        print(userInput)\n",
        "        myStr += response(userInput)\n",
        "\n",
        "        if ContextHistory.myFirstInput < 1:\n",
        "            ContextHistory.myFirstInput = 1\n",
        "    return str(myStr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUEseLRoCMD_"
      },
      "source": [
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zzmtu1GCPFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0d23ae-021c-4e48-8586-561606ee8c31"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://46c8b77ffe89.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [15/Apr/2021 09:34:20] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Apr/2021 09:34:20] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Apr/2021 09:34:21] \"\u001b[37mGET /static/pop.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [15/Apr/2021 09:34:21] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Apr/2021 09:34:33] \"\u001b[37mGET /get?msg=hello HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6.016000043018721e-06\n",
            "hello\n",
            "[('greeting', 0.99791116)]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [15/Apr/2021 09:34:34] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [15/Apr/2021 09:34:43] \"\u001b[37mGET /get?msg=check%20my%20symptoms%20please HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9.212738607999995\n",
            "check my symptoms please\n",
            "[('symptoms', 0.9999342)]\n",
            "Filter Not In Requested Object\n",
            "Please specify what physical and/or mental anxiety symptoms are more prevalent whilst at university during covid-19! I.E. 'I feel inferior to other students' or 'I have feelings of nausea'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [15/Apr/2021 09:34:55] \"\u001b[37mGET /get?msg=I%20am%20starting%20to%20feel%20very%20sick HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "21.62060266200001\n",
            "userChoiceOneGrp_I am starting to feel very sick\n",
            "[('physicalSymptom_MediumRisk', 0.9997011)]\n",
            "physSymp_medRsk_\n",
            "It is heavily advised that you meet with a member of the wellbeing team as a means to discuss your anxieties and symptom triggers in a professional and understanding environment as the physical symptoms you have specified that your state of anxiety has indicated that you may be suffering from a higher anxiety disorder in which is beyond the capabilities of the chatbot and indicates you may not be functioning/managing your stress/anxieties without the utilisation of professional help. Do you want me to redirect you to the wellbeing teams appointment page as to allow you to book an appointment with a member of the wellbeing team?\n",
            "symptomMentalOrPhysical\n",
            "reached\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}