{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "metmind.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwYlg8bwDhjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2acb5e-7165-4316-b90a-2b52061fd0b0"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNr2eHgMDtJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d321166-8cb6-4f56-bb15-0af31a0b2c29"
      },
      "source": [
        "pip install tflearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Nszpz-EkP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e25da3-0550-48f8-b03b-757315ea3849"
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxLcc0mJzsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568b7c7c-ed3c-4a07-bcc2-0978216f69de"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veLjVxEVqsDU"
      },
      "source": [
        "from IPython.display import Javascript"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gNHg_8uwQW6"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdtkJO5W-1gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76545c8-3401-4767-984f-ccaa86370486"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "import pickle\n",
        "import math\n",
        "import binascii\n",
        "import webbrowser\n",
        "import urllib.error\n",
        "import urllib.request\n",
        "import smtplib\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odEmd-yTF4lR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "334cb6bf-2ab7-42f7-8dfe-701817a39fcf"
      },
      "source": [
        "tf.version.VERSION"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_93JSb9EN8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570f094d-1a8b-49a5-ce4d-19c771a0e466"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGkGfl4MQpCX"
      },
      "source": [
        "qaCode = binascii.unhexlify(\"5468616e6b20796f7520666f722070617274696369706174696e6720666f72203130206d696e75746573212054686520436f646520666f7220746865207175657374696f6e6e61697265206973204135337274593133322120596f752063616e206b6565702074657374696e6720696620796f752077616e743a203c62722f3e3c62722f3e\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzpMkYfR_HHZ"
      },
      "source": [
        "try:\n",
        "  with open('intents.json') as json_data:\n",
        "      intents = json.load(json_data)\n",
        "except FileNotFoundError:\n",
        "  print(\"json file not found\")\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvIwj_TGl28J"
      },
      "source": [
        "files = [\"./templates/index.html\", \"./static/pop.mp3\", \"./static/css/style.css\"]\n",
        "for item in files:\n",
        "  if os.path.isfile(item):\n",
        "    continue\n",
        "  else:\n",
        "    print(item + \" does not exist in the correct directory! Please refer back to the guidelines found in the email\")\n",
        "    sys.exit('Closing Program')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSC66RZT_LfU"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ-S1zcL_Nlz"
      },
      "source": [
        "# loop through each sentence in our intents patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each word in the sentence\n",
        "        try:\n",
        "          w = nltk.word_tokenize(pattern)\n",
        "        except LookupError as ntlkerror:\n",
        "          print(\"Error during tokenization: \", ntlkerror)\n",
        "          sys.exit('Closing Program')\n",
        "\n",
        "        words.extend(w)\n",
        "        documents.append((w, intent['tag']))\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFMrXqRI_Qll"
      },
      "source": [
        "# stem and lower each word and remove duplicates\n",
        "try:\n",
        "  words = [stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
        "  words = sorted(list(set(words)))\n",
        "except IndexError:\n",
        "  print(\"Error stemming words\")\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sst6ntm_SjE"
      },
      "source": [
        "# remove duplicates\n",
        "classes = sorted(list(set(classes)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmNrwzZAAVRT"
      },
      "source": [
        "# create our training data\n",
        "training = []\n",
        "output = []\n",
        "# create an empty array for our output\n",
        "output_empty = [0] * len(classes)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehuJjHOoAYl0"
      },
      "source": [
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    bag_of_words = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # stem each word\n",
        "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "    # bag_of_words array\n",
        "    for w in words:\n",
        "      if w in pattern_words:\n",
        "        bag_of_words.append(1)\n",
        "      else:\n",
        "        bag_of_words.append(0)\n",
        "\n",
        "\n",
        "    # output is a '0' for each tag and '1' for current tag\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag_of_words, output_row])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9lWmzkZAmwG"
      },
      "source": [
        "# shuffle our features and turn into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njatqhJxAqY9"
      },
      "source": [
        "# create train and test lists\n",
        "train_x = list(training[:, 0])\n",
        "train_y = list(training[:, 1])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9-22d2AsaV"
      },
      "source": [
        "try:\n",
        "  tf.reset_default_graph()\n",
        "except AttributeError as tfgrapherror:\n",
        "  print(\"Error resetting tensorflow graph: \", tfgrapherror)\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb90R_4iAu_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4920c566-3a4d-41f0-82a2-6dc983ed0b81"
      },
      "source": [
        "try:\n",
        "  hiddenLayerNode = math.ceil(((len(train_x[0]) + len(train_y[0])) / 2))\n",
        "  net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "  net = tflearn.fully_connected(net, hiddenLayerNode)\n",
        "  net = tflearn.fully_connected(net, math.ceil((hiddenLayerNode / 2)))\n",
        "  net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
        "  net = tflearn.regression(net)\n",
        "except ValueError as nnbuilderror:\n",
        "  print(\"Error creating the neural network model: \", nnbuilderror)\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUfZldXcAFHN"
      },
      "source": [
        "if not os.path.isdir('./tflearnModel'):\n",
        "    try:\n",
        "        os.mkdir(\"./tflearnModel\")\n",
        "    except OSError:\n",
        "        print(\"Creation of the directory failed\")\n",
        "        sys.exit('Closing Program')\n",
        "    else:\n",
        "        print(\"Successfully created the directory\")\n",
        "        "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj_NZvXdAzRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bf909e-cf13-492c-ee2b-797be66d1317"
      },
      "source": [
        "# Define model and setup tensorboard\n",
        "try:\n",
        "  model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
        "  # Start training (apply gradient descent algorithm)\n",
        "  model.fit(train_x, train_y, n_epoch=100, batch_size=32, show_metric=True)\n",
        "  model.save('./tflearnModel/model.tflearn')\n",
        "except IndexError as nnfiterror:\n",
        "  print(\"Error fitting the neural network model: \", nnfiterror)\n",
        "  sys.exit('Closing Program')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 2499  | total loss: \u001b[1m\u001b[32m0.00236\u001b[0m\u001b[0m | time: 0.131s\n",
            "| Adam | epoch: 100 | loss: 0.00236 - acc: 0.9979 -- iter: 768/779\n",
            "Training Step: 2500  | total loss: \u001b[1m\u001b[32m0.00221\u001b[0m\u001b[0m | time: 0.138s\n",
            "| Adam | epoch: 100 | loss: 0.00221 - acc: 0.9981 -- iter: 779/779\n",
            "--\n",
            "INFO:tensorflow:/content/tflearnModel/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0A_DTioA4Ok"
      },
      "source": [
        "try:\n",
        "  pickle.dump({'words': words, 'classes': classes, 'train_x': train_x, 'train_y': train_y},\n",
        "              open(\"./tflearnModel/model.tflearn\", \"wb\"))\n",
        "except (IOError, OSError, pickle.PickleError, pickle.UnpicklingError):\n",
        "  print(\"Error writing/saving pickled data as tflearn model\")\n",
        "  sys.exit(\"Closing Program\")\n",
        "except FileNotFoundError:\n",
        "  print(\"tflearn model does not exist\")\n",
        "  sys.exit(\"Closing Program\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aBNbR_8A-Gq"
      },
      "source": [
        "try:\n",
        "  data = pickle.load(open(\"./tflearnModel/model.tflearn\", \"rb\"))\n",
        "except (IOError, OSError, pickle.PickleError, pickle.UnpicklingError):\n",
        "  print(\"Error loading pickled data from tflearn model\")\n",
        "  sys.exit(\"Closing Program\")\n",
        "except FileNotFoundError:\n",
        "  print(\"tflearn model does not exist\")\n",
        "  sys.exit(\"Closing Program\")\n",
        "\n",
        "words = data['words']\n",
        "classes = data['classes']\n",
        "train_x = data['train_x']\n",
        "train_y = data['train_y']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L16OwfUJBD2d"
      },
      "source": [
        "class ContextHistory:\n",
        "    contextOld = \"\"\n",
        "    myIntent = \"\"\n",
        "    myOldTag = \"\"\n",
        "    myTag = \"\"\n",
        "    myFirstContext = \"\"\n",
        "\n",
        "    myFirstInput = 0\n",
        "\n",
        "    myEmailIntent = 0\n",
        "    studentEmail = \"\"\n",
        "    studentPassword = \"\"\n",
        "    staffEmail = \"\"\n",
        "    symptomType = \"\"\n",
        "    symptomProblem = \"\"\n",
        "\n",
        "    time = 0.0\n",
        "    startTime = 0.0\n",
        "\n",
        "    chatRestart = \"<br/><br/>Please specify if you want \" \\\n",
        "                  \"guidance for your <fears> or anxiety <symptoms> whilst at Cardiff Met during the coronavirus \" \\\n",
        "                  \"epidemic. Input (fears) or (symptoms)\"\n",
        "myOldContext = ContextHistory()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA4hJzDiBYb0"
      },
      "source": [
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMxUkZQsBcIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff4dde6-2cfe-4d94-b9b9-2d395031bf6d"
      },
      "source": [
        "model.load('./tflearnModel/model.tflearn')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/tflearnModel/model.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B72wL7GdBfcy"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stem each word\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4wvklXfBi86"
      },
      "source": [
        "def bow(sentence, words, show_details=False):\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    bag_of_words = [0] * len(words)\n",
        "    for s in sentence_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag_of_words[i] = 1\n",
        "                if show_details:\n",
        "                    print(\"found in bag: %s\" % w)\n",
        "\n",
        "    return np.array(bag_of_words)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8mOrk-xBl68"
      },
      "source": [
        "def myTime():\n",
        "    if ContextHistory.myFirstInput < 1:\n",
        "        ContextHistory.startTime = time.perf_counter()\n",
        "\n",
        "    ContextHistory.time = (time.perf_counter() - ContextHistory.startTime)\n",
        "    print(ContextHistory.time)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoCjWt8hBomo"
      },
      "source": [
        "# create a data structure to hold user context\n",
        "context = {}"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNLHHc-QBrQG"
      },
      "source": [
        "ERROR_THRESHOLD = 0.70"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ63hKEOBs9O"
      },
      "source": [
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    results = model.predict([bow(sentence, words)])[0]\n",
        "    # filter out predictions below a threshold\n",
        "    results = [[i, r] for i, r in enumerate(results) if r > ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return return_list"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpifGB7VB1H4"
      },
      "source": [
        "def filtering(i, show_details):\n",
        "    if 'context_set' in i:\n",
        "        if show_details:\n",
        "            return 'context:', i['context_set']\n",
        "        myOldContext.contextOld = i['context_set']\n",
        "        myOldContext.myTag = i['tag']\n",
        "        return i['context_set']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKl5hIHLB5Bs"
      },
      "source": [
        "def advancedResponse(i):\n",
        "    if 'web' in i:\n",
        "        myWeb = i['web']\n",
        "        try:\n",
        "            urllib.request.urlopen(myWeb)\n",
        "        except urllib.error.HTTPError:\n",
        "            return \"I am sorry but I am having trouble connecting to the site: \" + random.choice(i['responses'])\n",
        "        except urllib.error.URLError:\n",
        "            return \"I am sorry but I am having trouble connecting to the site\" + random.choice(i['responses'])\n",
        "        else:\n",
        "            url = myWeb\n",
        "            display(Javascript('window.open(\"{url}\");'.format(url=url)))\n",
        "            return \"Redirecting: \" + random.choice(i['responses'])\n",
        "\n",
        "    else:\n",
        "        return random.choice(i['responses'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wn2oKK_B764"
      },
      "source": [
        "def email(userInput):\n",
        "    if myOldContext.myEmailIntent == 1:\n",
        "        myOldContext.studentEmail = str(userInput) + \"@outlook.cardiffmet.ac.uk\"\n",
        "        print(str(userInput) + \"from email\")\n",
        "        myOldContext.myEmailIntent += 1\n",
        "        return \"Please Enter Your Student Password\"\n",
        "    else:\n",
        "        recEmail = myOldContext.staffEmail\n",
        "        subject = myOldContext.studentEmail + \" \" + myOldContext.symptomType + \" anxiety symptom issues\"\n",
        "        body = \"Dear Sir/Madam,\\n\\n This student has been recorded at a high priority as the participant has shown \" \\\n",
        "               \"signs of suffering from severe \" + myOldContext.symptomType + \" anxiety symptoms. The symptoms \" \\\n",
        "                                                                              \"specified indicate that the \" \\\n",
        "                                                                              \"student could be suffering from \" \\\n",
        "                                                                              \"anxities that can lead to \" + \\\n",
        "               myOldContext.symptomProblem + \"\\n\\nPlease Email them as soon as possible as to arrange a formal meetup \" \\\n",
        "                                             \"and/or conversation. \\n\\n Kindest Regards\\nMetMind Chatbot\"\n",
        "        msg = f'Subject: {subject}\\n\\n{body}'\n",
        "\n",
        "        myOldContext.studentPassword = str(userInput)\n",
        "\n",
        "        try:\n",
        "            server = smtplib.SMTP('smtp.outlook.com', 587)\n",
        "            server.starttls()\n",
        "            server.login(myOldContext.studentEmail, myOldContext.studentPassword)\n",
        "            server.sendmail(myOldContext.studentEmail, recEmail, msg)\n",
        "            myOldContext.myEmailIntent = 0\n",
        "            myOldContext.contextOld = \"\"\n",
        "\n",
        "            myOldContext.myIntent = \"\"\n",
        "            myOldContext.myOldTag = myOldContext.chatRestart\n",
        "            return \"email sent! you will hear from the wellbeing team shortly\" + myOldContext.chatRestart\n",
        "        except smtplib.SMTPAuthenticationError:\n",
        "            myOldContext.myEmailIntent = 1\n",
        "            return \"Incorrect email or password: please enter your username\""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3yTCLpsCAOo"
      },
      "source": [
        "def response(sentence, userID='123', show_details=False):\n",
        "    results = classify(sentence)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "    if results:\n",
        "        # loop as long as there are matches to process\n",
        "        print(results)\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                # find a tag matching the first result\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    \n",
        "                    if 'email' in i:\n",
        "                        myOldContext.myEmailIntent = 1\n",
        "                        myOldContext.staffEmail = i['email']\n",
        "                        myOldContext.symptomType = i['symptom_type']\n",
        "                        myOldContext.symptomProblem = i['symptom_problem']\n",
        "\n",
        "                    if 'context_set' in i and 'context_filter' not in i and myOldContext.myFirstContext == \"\":\n",
        "                        myOldContext.myOldTag = random.choice(i['responses'])\n",
        "                        myOldContext.myFirstContext = i['context_set']\n",
        "                        myOldContext.myIntent = i['intent']\n",
        "\n",
        "                    try:\n",
        "                        if ('intent' in i and i['context_filter'] == myOldContext.contextOld) or (i['tag'] == myOldContext.myTag):\n",
        "                            myOldContext.myOldTag = random.choice(i['responses'])\n",
        "                            myOldContext.myIntent = i['intent']\n",
        "                            print(myOldContext.myIntent)\n",
        "\n",
        "                    except KeyError:\n",
        "                        print(\"Filter Not In Requested Object\")\n",
        "\n",
        "                    \n",
        "                    print(myOldContext.myOldTag)\n",
        "                    print(myOldContext.contextOld)\n",
        "\n",
        "                    if 'context_filter' in i and i['context_filter'] == myOldContext.contextOld:\n",
        "                        context[userID] = filtering(i, show_details)\n",
        "                        if 'context_set' not in i and myOldContext.myEmailIntent < 1:\n",
        "                            myOldContext.contextOld = \"\"\n",
        "                            myOldContext.myIntent = \"\"\n",
        "                            myOldContext.myFirstContext = \"\"\n",
        "                            myOldContext.myOldTag = myOldContext.chatRestart\n",
        "                            myResp = advancedResponse(i) + myOldContext.chatRestart\n",
        "                        else:\n",
        "                            myResp = advancedResponse(i)\n",
        "                        print(\"reached\")\n",
        "                        return myResp\n",
        "                    elif 'context_filter' not in i and myOldContext.contextOld != \"\" or (\n",
        "                            'context_filter' in i and i['context_filter'] != myOldContext.contextOld):\n",
        "                        return \"I'm sorry? Can you repeat that?: \" + myOldContext.myOldTag\n",
        "                    else:\n",
        "                        context[userID] = filtering(i, show_details)\n",
        "\n",
        "                        if 'context_filter' not in i or \\\n",
        "                                (userID in context and 'context_filter' in i and i['context_filter'] == context[\n",
        "                                    userID]):\n",
        "                            if show_details:\n",
        "                                return 'tag:', i['tag']\n",
        "                            # a random response from the intent\n",
        "                            return random.choice(i['responses'])\n",
        "\n",
        "            results.pop(0)\n",
        "    else:\n",
        "        if myOldContext.myIntent != \"\":\n",
        "            return \"I'm sorry? Can you repeat that?: \" + myOldContext.myOldTag\n",
        "        else:\n",
        "            return \"I'm sorry? Can you repeat that?: \" + myOldContext.myOldTag"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4otdGb7HCHZt"
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3d6UXFNCJYo"
      },
      "source": [
        "@app.route('/get')\n",
        "def userChat():\n",
        "    myStr = \"\"\n",
        "    if ContextHistory.time > 600.00 and ContextHistory.myFirstInput != 2:\n",
        "        ContextHistory.myFirstInput = 2\n",
        "\n",
        "        myStr += qaCode.decode()\n",
        "\n",
        "\n",
        "    userInput = request.args.get('msg')\n",
        "\n",
        "    myTime()\n",
        "\n",
        "    if myOldContext.myEmailIntent != 0:\n",
        "        myStr = email(userInput)\n",
        "    else:\n",
        "        if myOldContext.myIntent != \"\":\n",
        "            userInput = myOldContext.myIntent + userInput\n",
        "        print(userInput)\n",
        "        myStr += response(userInput)\n",
        "\n",
        "        if ContextHistory.myFirstInput < 1:\n",
        "            ContextHistory.myFirstInput = 1\n",
        "    return str(myStr)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUEseLRoCMD_"
      },
      "source": [
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zzmtu1GCPFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6369622-5bbb-4cb3-e3d0-cb307eba2363"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0ff5728bf073.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Apr/2021 15:54:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Apr/2021 15:54:30] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Apr/2021 15:54:30] \"\u001b[37mGET /static/pop.mp3 HTTP/1.1\u001b[0m\" 206 -\n",
            "127.0.0.1 - - [04/Apr/2021 15:54:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Apr/2021 15:54:33] \"\u001b[37mGET /get?msg=fears HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5.38099993718788e-06\n",
            "fears\n",
            "[('fearGroup', 0.9943064)]\n",
            "Filter Not In Requested Object\n",
            "Please specify what you are most fearful of whilst at university during the Covid-19 Epidemic! I.E. 'I am scared that the new block system will affect my grades'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Apr/2021 15:54:34] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Apr/2021 15:54:37] \"\u001b[37mGET /get?msg=Failing%20My%20Assignments HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3.6474441420000403\n",
            "usrChoiceTwoGroup_Failing My Assignments\n",
            "[('fear_Educational', 0.9999763)]\n",
            "uniFearedEducateCon1_\n",
            "The new block/educational system has put a lot of strain on the students but due to the coronavirus then this is unlikely to change for the foreseeable future. Therefore, it is critical to conduct efficient time-management plans as to efficiently ensure you can incorporate personal time to participate in hobbies whilst conducting your studies and assignments as to prevent being overburdened/burned-out whilst ensuring that such assignments are completed on time as to reduce risks of anxiety whilst ensuring you get the mark you deserve. Would you like to know about some of the services available from the university?\n",
            "coronaFrs\n",
            "reached\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Apr/2021 15:54:41] \"\u001b[37mGET /get?msg=no HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7.431502836999925\n",
            "uniFearedEducateCon1_no\n",
            "[('fear_Educational2_ConsentNo', 0.99657)]\n",
            "The new block/educational system has put a lot of strain on the students but due to the coronavirus then this is unlikely to change for the foreseeable future. Therefore, it is critical to conduct efficient time-management plans as to efficiently ensure you can incorporate personal time to participate in hobbies whilst conducting your studies and assignments as to prevent being overburdened/burned-out whilst ensuring that such assignments are completed on time as to reduce risks of anxiety whilst ensuring you get the mark you deserve. Would you like to know about some of the services available from the university?\n",
            "fearEducational1\n",
            "reached\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Apr/2021 15:54:46] \"\u001b[37mGET /get?msg=fears HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12.878699638999933\n",
            "fears\n",
            "[('fearGroup', 0.9943064)]\n",
            "Filter Not In Requested Object\n",
            "Please specify what you are most fearful of whilst at university during the Covid-19 Epidemic! I.E. 'I am scared that the new block system will affect my grades'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Apr/2021 15:54:48] \"\u001b[37mGET /get?msg=hgfghffgh HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14.796259886999906\n",
            "usrChoiceTwoGroup_hgfghffgh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Apr/2021 15:56:19] \"\u001b[37mGET /get?msg=symptom HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "105.96691388799991\n",
            "usrChoiceTwoGroup_symptom\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}